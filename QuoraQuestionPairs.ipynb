{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.fillna(\"\")\n",
    "test_data = test.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import gensim\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def text_cleaning(text):\n",
    "    tokens = list(gensim.utils.tokenize(text, deacc=True, lower=True))\n",
    "    #find out if converting to lower case helps?\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [word.translate(table) for word in tokens]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in stripped if not word in stop_words]\n",
    "    words = [word if word.isalpha() else 'number' for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_questions = list(set(train_data['question1'].astype('U') + train_data['question2'].astype('U') + test_data['question1'].astype('U') + test_data['question2'].astype('U'))) \n",
    "for i in range(len(list_of_questions)):\n",
    "    if(type(list_of_questions[i]) is not str):\n",
    "        list_of_questions[i] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#word2vec = Word2Vec.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "word2vec = KeyedVectors.load_word2vec_format('Googleword2vec', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data[0:50000]\n",
    "test_data = test_data[0:100000]\n",
    "for dataset in [train_data, test_data]:\n",
    "    question1_tokens = list(range(len(dataset)))\n",
    "    question2_tokens = list(range(len(dataset)))\n",
    "    for idx, row in dataset.iterrows():\n",
    "        question1_tokens[idx] = text_cleaning(row['question1'])\n",
    "        question2_tokens[idx] = text_cleaning(row['question2'])\n",
    "    dataset.loc[:, 'question1_tokenized'] = question1_tokens\n",
    "    dataset.loc[:, 'question2_tokenized'] = question2_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def bag_of_words(value, corpus):\n",
    "    count_vector = CountVectorizer()\n",
    "    count_vector.fit_transform(corpus)\n",
    "    return count_vector.transform(value).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [train_data, test_data]:\n",
    "    question1_bow = list(range(len(dataset)))\n",
    "    question2_bow = list(range(len(dataset)))\n",
    "    for idx, row in dataset.iterrows():\n",
    "        corpus = [row['question1'], row['question2']]\n",
    "        question1_bow[idx] = bag_of_words(row['question1_tokenized'], corpus)\n",
    "        question2_bow[idx] = bag_of_words(row['question2_tokenized'], corpus)\n",
    "    dataset.loc[:, 'question1_bag_vector'] = question1_bow\n",
    "    dataset.loc[:, 'question2_bag_vector'] = question2_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi_distance(value1, value2):\n",
    "    if(len((set(value1).union(set(value2)))) == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        set_intersect = len(set(value1).intersection(set(value2)))\n",
    "        set_union = len(set(value1).union(set(value2)))\n",
    "        return (set_intersect)/(set_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [train_data, test_data]:\n",
    "    distance = list(range(len(dataset)))\n",
    "    for idx, row in dataset.iterrows():\n",
    "        distance[idx] = jacobi_distance(row['question1_tokenized'], row['question2_tokenized'])\n",
    "    dataset.loc[:, 'jacobi_distance'] = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance\n",
    "\n",
    "for dataset in [train_data, test_data]:\n",
    "    edit_dist = list(range(len(dataset)))\n",
    "    for idx, row in dataset.iterrows():\n",
    "        edit_dist[idx] = editdistance.eval(row['question1_tokenized'], row['question2_tokenized'])\n",
    "    dataset.loc[:, 'edit_distance'] = edit_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TFIDF\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit_transform(list_of_questions)\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "def summerizeWordVecs(words):\n",
    "    question_rep = np.zeros(embedding_dim)\n",
    "    if(len(words) == 0):\n",
    "        return question_rep\n",
    "    else:\n",
    "        for word in words:\n",
    "            if word in word2vec.vocab:\n",
    "                word_vector = word2vec.get_vector(word)\n",
    "            else:\n",
    "                word_vector = [np.random.randn(1) for i in range(embedding_dim)]\n",
    "            try:\n",
    "                idf = word2tfidf[str(word)]\n",
    "            except:\n",
    "                idf = 0\n",
    "            for i in range(embedding_dim):\n",
    "                question_rep[i] = question_rep[i] + word_vector[i]*idf\n",
    "        return question_rep/len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [train_data, test_data]:\n",
    "    dataset.loc[:, 'question1_summerized'] = dataset['question1']\n",
    "    dataset.loc[:, 'question2_summerized'] = dataset['question2']\n",
    "    for idx, row in dataset.iterrows():\n",
    "        dataset.at[idx, 'question1_summerized'] = summerizeWordVecs(row['question1_tokenized'])\n",
    "        dataset.at[idx, 'question2_summerized'] = summerizeWordVecs(row['question2_tokenized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "def find_cosine_similarity(value1, value2):\n",
    "    productValue = sum(value1*value2)\n",
    "    if(productValue != 0):\n",
    "        return 1 - spatial.distance.cosine(value1, value2)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [train_data, test_data]:\n",
    "    cs_w2v = list(range(len(dataset)))\n",
    "    cs_bow = list(range(len(dataset)))\n",
    "    for idx, row in dataset.iterrows():\n",
    "        cs_w2v[idx] = find_cosine_similarity(row['question1_summerized'], row['question2_summerized'])\n",
    "        if((len(row['question1_bag_vector']) == 0) | (len(row['question2_bag_vector']) == 0)):\n",
    "            cs_bow[idx] = 0  \n",
    "        else:\n",
    "            cs_bow[idx] = find_cosine_similarity(np.array(row['question1_bag_vector']).mean(axis=0), np.array(row['question2_bag_vector']).mean(axis=0))\n",
    "    dataset.loc[:, 'cosine_sim_w2v'] = cs_w2v\n",
    "    dataset.loc[:, 'cosine_sim_bow'] = cs_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('preprocessed_train_data_1.csv')\n",
    "test_data.to_csv('preprocessed_test_data_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv(\"preprocessed_train_data.csv\")\n",
    "test_data = pd.read_csv(\"preprocessed_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['cosine_sim_w2v','cosine_sim_bow','edit_distance','jacobi_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, valid_set, train_labels, valid_labels = train_test_split(train_data[features], train_data['is_duplicate'], test_size=0.3, random_state=4327)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "svm_clf = SVC(probability=True)\n",
    "svm_clf.fit(train_set, train_labels)\n",
    "\n",
    "#randforest_clf = RandomForestClassifier(n_estimators=300,min_samples_split=3,oob_score=True,n_jobs=-1, random_state = 4273, max_depth=5, bootstrap=True)\n",
    "#randforest_clf.fit(train_set, train_labels)\n",
    "\n",
    "#adaboost_clf = AdaBoostClassifier()\n",
    "#adaboost_clf.fit(train_set, train_labels)\n",
    "\n",
    "#xgboost_clf = XGBClassifier()\n",
    "#xgboost_clf.fit(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.82      0.75     21959\n",
      "          1       0.57      0.40      0.47     13041\n",
      "\n",
      "avg / total       0.65      0.67      0.65     35000\n",
      "\n",
      "Validation error\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.82      0.76      9392\n",
      "          1       0.58      0.40      0.47      5608\n",
      "\n",
      "avg / total       0.65      0.67      0.65     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predict_valid_set = svm_clf.predict(valid_set)\n",
    "predict_valid_set = predict_valid_set.reshape(len(predict_valid_set),1)\n",
    "print(\"Training error\")\n",
    "print(classification_report(train_labels, svm_clf.predict(train_set)))\n",
    "print(\"Validation error\")\n",
    "print(classification_report(valid_labels, predict_valid_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.665\n",
      "Accuracy: 0.666\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=6)\n",
    "\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(svm_clf, train_set, train_labels, cv=kfold, scoring= scoring)\n",
    "\n",
    "print(\"Accuracy: %.3f\"%results.mean())\n",
    "\n",
    "results = model_selection.cross_val_score(svm_clf, valid_set, valid_labels, cv=kfold, scoring= scoring)\n",
    "print(\"Accuracy: %.3f\"%results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss: -0.599\n",
      "Logloss: -0.596\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "scoring = 'neg_log_loss'\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=6)\n",
    "results = model_selection.cross_val_score(svm_clf, train_set, train_labels, cv=kfold, scoring = scoring)\n",
    "\n",
    "print(\"Logloss: %.3f\"%results.mean())\n",
    "\n",
    "results = model_selection.cross_val_score(svm_clf, valid_set, valid_labels, cv=kfold, scoring = scoring)\n",
    "\n",
    "print(\"Logloss: %.3f\"%results.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
